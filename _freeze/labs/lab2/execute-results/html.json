{
  "hash": "5c60a7b8a33d33f7731d934bbce09706",
  "result": {
    "markdown": "---\ntitle: \"Exploratory Data Analysis with ![](../img/Rlogo.png){width=60px}\"\nsubtitle: <span style=\"color:#2C3E50\">11.S954 Applied Data Science for Cities</span>\ndate: \"Last Updated 2023-10-18\"\nformat: html\neditor: visual\n---\n\n\n# Overview\n\nThis week's Lab Exercise focuses on the [dplyr](https://dplyr.tidyverse.org/index.html) package and the [ggplot2](https://ggplot2.tidyverse.org) package. It also begins to engage with data visualization best practices by demonstrating how to create and interpret a variety of graphics.\n\n**Exploratory data analysis (EDA)** is a phase of a larger data science workflow---or perhaps a philosophy---that emphasizes getting to know the data before rushing to analyze it using this more rigid approaches like hypothesis tests. EDA relies heavily on the creation and interpretation of **graphics** in order to build familiarity and gain fundamental insights that can inform more sophisticated analyses later on. There are several overarching goals of exploratory data analysis, including:\n\n1.  To determine if there are any problems with your dataset.\n2.  To determine whether the question you are asking can be answered by the data that you have.\n3.  To begin formulating an answer to your question.\n\n# Our study topic today\n\nIn the 2017 [Tax Cuts and Jobs Act](https://www.congress.gov/115/bills/hr1/BILLS-115hr1enr.pdf), a new federal incentive was introduced to encourage investment in low-income and undercapitalized communities. States were given the chance to select specific census tracts as Opportunity Zones, where investors could enjoy tax benefits for their eligible investments. Although, there's been [a lot of curiosity](https://www.urban.org/policy-centers/metropolitan-housing-and-communities-policy-center/projects/opportunity-zones) among practitioners and researchers regarding how effective the program is and whether the designations made by governors were successful.\n\nIf you are interested in the locations of these Opportunity Zones, you can check out [this map](https://opportunityzones.hud.gov/resources/map). The pink geometries reflected on the map are [census tracts](https://www.census.gov/programs-surveys/geography/about/glossary.html#par_textimage_13), which we often use as a proxy for neighborhoods, especially in urban areas. Just find a familiar place, and see which areas have been designated as Opportunity Zones.\n\n## Download data and load packages\n\nNow please navigate to Urban Institute's website about [Opportunity Zones](https://www.urban.org/policy-centers/metropolitan-housing-and-communities-policy-center/projects/opportunity-zones), find the link \"Download tract-level data on all Opportunity Zones\", and **download this dataset** to your \"data\" folder within your Lab 2 project folder. Open it in Excel and take a quick look. This data lists tracts nationwide that were designated an Opportunity Zones, along with essential Census demographic data that describe these tracts.\n\nTo stay organized, you should load packages at the beginning of your script or markdown document. These are the three packages we are going to use today.\n\n\n\n\n\n# Read and examine our data\n\nUse `read_xlsx` from the `readxl` package will read Microsoft Excel files into data tables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs <- read_xlsx(\"../data/urbaninstitute_tractlevelozanalysis_update01142021.xlsx\")\n```\n:::\n\n\nNow look at the \"Environment\" panel on the top-right of your R interface, you should see the new variable `ozs`. You can also see this variable 27 variables (columns) and 42178 observations (rows). Click it to preview the content of `ozs`. Alternatively, you could preview it by typing `View(ozs)` in your console.\n\nHere are the column definitions:\n\n-   **geoid**: combined state, county, tract FIPS (Federal Information Processing Standards) code this is a unique identification number for each census tract. If it is the first time you heard of tracts, they are sub-areas of a county defined for the purpose of taking a census.\n-   **state**: the name of the state\n-   **county**: the county name\n-   **Designated**: 1 if the tract was designated an Opportunity Zone\n-   **Type**: category for OZ designation\n-   **Population**: total population\n-   **PovertyRate**: poverty rate\n-   **medhhincome**: median household income\n-   **medrent**: median gross rent (per month)\n-   **vacancyrate**: residential vacancy rate\n-   **unemprate:** unemployment rate\n-   **pctwhite**: White non-Hispanic population (%)\n-   **pctblack**: Black non-Hispanic population (%)\n-   **pctHispanic**: Hispanic and Latino population (%)\n-   **Metro**: tract in a metropolitan area\n\n------------------------------------------------------------------------\n\n### Your practice\n\nThere are commonly used commands in base R that provide an initial check of a dataset, for example:\n\n-   `dim()`, `ncol()`, `nrow()`\n-   `colnames()`\n-   `glimpse()`\n-   `head()`, `tail()`\n-   `str()`\n-   `summary()`\n\nInsert a new code chunk and experiment with a few of these functions. What each function accomplishes?\n\n------------------------------------------------------------------------\n\nBeside examining the basic data structures, There are a few other things I'll encourage you to inspect during the initial check process:\n\n**Completeness**\n\nBy viewing the first several rows of the dataset, we can already spot some N/A values. For example, there is a field named `Designated` which is 1 when an eligible tract was designated as an opportunity zone, and N/A where the tract was not designated. (In fact, for our analysis, it's better to recode these NAs to equal 0 instead, which we will do in a bit).\n\nThere are N/As in many of the statistics fields as well, which indicate unavailable information for that specific data point. (If you never see \"N/A\" in the first 20 some rows, it will be too soon).\n\nHow many missing values are there and would that be a hurdle for my analysis? It will be great to have a sense of completeness in terms of what proportion of a field actually holds data. `DataExplorer` is a handy tool to quickly understand datasets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDataExplorer::plot_missing(ozs)\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/missingvalues-1.png){width=672}\n:::\n:::\n\n\n**Unique values of categorical variables**\n\nThe `unique()` base R function extracts unique elements in a large set of values. We can use it to specific columns to see what entries we have here. It also helps us to see if there is anything we need to clean up, such as typos or incorrect names, before proceeding to more analysis. For this dataset, we can take a look at the `state` column. What we have here in this column are all U.S. territories as well as a few NA values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(ozs$state) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Alabama\"                  \"Alaska\"                  \n [3] \"Arizona\"                  \"Arkansas\"                \n [5] \"California\"               \"Colorado\"                \n [7] \"Connecticut\"              \"Delaware\"                \n [9] \"District of Columbia\"     \"Florida\"                 \n[11] \"Georgia\"                  \"Hawaii\"                  \n[13] \"Idaho\"                    \"Illinois\"                \n[15] \"Indiana\"                  \"Iowa\"                    \n[17] \"Kansas\"                   \"Kentucky\"                \n[19] \"Louisiana\"                \"Maine\"                   \n[21] \"Maryland\"                 \"Massachusetts\"           \n[23] \"Michigan\"                 \"Minnesota\"               \n[25] \"Mississippi\"              \"Missouri\"                \n[27] \"Montana\"                  \"Nebraska\"                \n[29] \"Nevada\"                   \"New Hampshire\"           \n[31] \"New Jersey\"               \"New Mexico\"              \n[33] \"New York\"                 \"North Carolina\"          \n[35] \"North Dakota\"             \"Ohio\"                    \n[37] \"Oklahoma\"                 \"Oregon\"                  \n[39] \"Pennsylvania\"             \"Rhode Island\"            \n[41] \"South Carolina\"           \"South Dakota\"            \n[43] \"Tennessee\"                \"Texas\"                   \n[45] \"Utah\"                     \"Vermont\"                 \n[47] \"Virginia\"                 \"Washington\"              \n[49] \"West Virginia\"            \"Wisconsin\"               \n[51] \"Wyoming\"                  \"American Samoa\"          \n[53] NA                         \"Guam\"                    \n[55] \"Northern Mariana Islands\" \"Puerto Rico\"             \n[57] \"Virgin Islands\"          \n```\n:::\n:::\n\n\n**Range of numerical variables**\n\nFor numeric columns, it'll be helpful to visually inspect whether the values fall within the expected range, how the values are distributed, and whether there are any wacky numbers like -999 (often used in SPSS files to indicate missing data), etc. A quick histogram helps us to see the value distribution. Additionally, it visualizes patterns by dividing the data set into groups (or bins) of equal length, then communicating how many or what proportion of the observations fall within each of those \"bins\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# We can use the base R function hist() to check one variable:\nhist(ozs$Population)\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/hist-1-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Or use the DataExplorer package to check multiple variables at the same time\nDataExplorer::plot_histogram(ozs[,c(10:13)])\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/hist-2-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Your practice\n\nCheck the `DesignatedOZ` column - what values does it contain?\n\n------------------------------------------------------------------------\n\n# Data Cleanning\n\nThe Urban Institute has coded the designated variable as either taking a value of 1 when designated or NA when not. We can recode the NA values in `DesignatedOZ` for legibility. In the following code, we uses the `dplyr` function: `mutate` to modify `DesignatedOZ` in place. We replaced the numbers with texts since the NA and 1 here have no mathematical meaning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs <- ozs |> mutate(DesignatedOZ = \n                ifelse(is.na(DesignatedOZ), \"Not Designated\", \"Designated\"))\n```\n:::\n\n\nThere are a few columns (such as `SE_Flag`) that we won't need for this analysis. We can use `select` in `dplyr` function to select a subset of columns to work on. `select` allows you to retain specified columns. If there is a minus sign in front, that means to drop these specified columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs <- ozs |> select(-c(dec_score, SE_Flag, Metro, Micro, NoCBSAType))\n```\n:::\n\n\n# Exploring Variation Within Variables\n\nThe code chunk below creates a **boxplot** to contrast the distribution of poverty rates between designated opportunity zones and undesignated zones. A boxplot is a very commonly used EDA tool that allows us to quickly visualize the distribution of a single variable or column of data if we are working with a data frame. Note that we are using what should now be familiar conventions to construct the graphic beginning with the `ggplot` function, then adding more features with the `+` operator and other functions [listed in the package reference](https://ggplot2.tidyverse.org/reference/index.html).\n\n-   `ggplot(data = ozs)`: This is the main plotting function. `ozs` is your dataset we use.\n-   `geom_boxplot()`: Recall that geometric layers are called **geoms**. It tells R what kind of geometry you want to use visualize the data.\n-   `aes(x = DesignatedOZ, y = PovertyRate)`: The `aes()` function is where you tell `ggplot` which variable goes on the x axis followed by which variable goes on the y axis.\n-   The `labs` function sets the labels. Because the legend is showing the **fill** component of the plot, we use the **fill** argument in the `labs` function to set the name of the legend itself.\n-   We used a new function `scale_y_continuous` to specify y axis properties. Here we are making sure the poverty rate are labeled as **percentages**. If you remove this line, they will by default show as decimal numbers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = ozs) +\n  geom_boxplot(aes(x = DesignatedOZ, y = PovertyRate, fill = DesignatedOZ)) + \n  scale_y_continuous(labels = scales::percent) +\n  labs(title = \"\", x = \"Opportunity Zone Eligible Tracts\", y = \"Poverty Rate\", fill = \"Tracts\")\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/boxplot-1.png){width=672}\n:::\n:::\n\n\nWe can create **cross-tabulations** as a complement to visual EDA tools like boxplots and histograms. An easy way to do this is to use the existing function `count` in the `dplyr` package. A brief demonstration is given in the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs |> \n  count(state, DesignatedOZ)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 108 × 3\n   state          DesignatedOZ       n\n   <chr>          <chr>          <int>\n 1 Alabama        Designated       158\n 2 Alabama        Not Designated   677\n 3 Alaska         Designated        25\n 4 Alaska         Not Designated    43\n 5 American Samoa Designated        16\n 6 Arizona        Designated       168\n 7 Arizona        Not Designated   702\n 8 Arkansas       Designated        85\n 9 Arkansas       Not Designated   435\n10 California     Designated       879\n# ℹ 98 more rows\n```\n:::\n:::\n\n\n### Exercise 1\n\nInsert a new code chunk and a markdown section below this one to \"catch\" your responses. Please review what we have learned and proceed with the questions below.\n\n1.  Which of the variables (columns) are continuous and which are categorical (e.g., factor)?\n    -   Hint: Recall that a variable is categorical if it can only take one of a small set of values and continuous if it can take any of an infinite set of ordered values.\n    -   Which function or approach did you use to answer this question?\n2.  How is the median household income distributed across the places?\n    -   Hint: Should we expect to see a more flat/homogeneous distribution, or a more skewed distribution in terms of fewer households belonging to the higher-income group?\n    -   Which function or approach did you use to answer this question?\n3.  Create a graphic that contrasts the distribution of the unemployment rate in designated zones and in undesignated zones in this dataset.\n    -   Interpret the graphic(s) you have created and include 2-3 sentences of text explanation (i.e., in an RMarkdown section)\n\n# Exploring Variation Between Variables\n\nWe are often interested in bivariate relationships or how two variables relate to one another. **Scatterplots** are often used to visualize the association between two **continuous variables**. They can reveal much about the [nature of the relationship](https://www.jmp.com/en_hk/statistics-knowledge-portal/exploratory-data-analysis/scatter-plot.html) between two variables.\n\nLet's use a subset of our data - tracts in Massachusetts - to perform this part of analysis. You can definitely use the entire dataset, it's just there will be over 40,000 points showing on the graph.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs_ma <- ozs |> filter(state == \"Massachusetts\") \n```\n:::\n\n\nNow we begin by creating a scatterplot of poverty rate and unemployment rate. Note that we used `theme_bw`, which is a [`theme` template](https://ggplot2.tidyverse.org/reference/ggtheme.html) for a cleaner look.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ozs_ma) +\n  geom_point(aes(unemprate, PovertyRate)) +\n  labs(title = \"Poverty rate vs. unemployment rate in Opportunity Zone eligible tracts\", \n       subtitle = \"State of Massachusetts\",\n       x = \"Unemployment rate\",\n       y = \"Poverty rate\",\n       caption = \"Source: Urban Institute (2018)\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/Scatterplot-Copper-1.png){width=672}\n:::\n:::\n\n\nIt is generally easy to recognize patterns in a graphical display. As we move from left to right along the x-axis (i.e., as unthe employment rate creases), the amount of poverty rate reported also increases.\n\nAs a complement to the scatterplot, we can use the base R `cor` function to calculate the (Pearson by default, see the documentation for other options) **correlation** between any continuous variables in the dataset. The `DataExplorer` package is also designed to help us quickly understand patterns in our data. We demonstrate both in the following code.\n\nIf you are unfamiliar with reading a correlation matrix, the values range between -1 and 1 where:\n\n-   -1 indicates a perfectly negative linear correlation between two variables\n-   0 indicates no linear correlation between two variables\n-   1 indicates a perfectly positive linear correlation between two variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs_ma |> select(Population:medrent, pctwhite:BAorhigher) |> \n  na.omit() |> \n  stats::cor(use = \"complete.obs\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                Population medhhincome PovertyRate  unemprate    medvalue\nPopulation    1.0000000000   0.1971310 -0.17219731 -0.1255690  0.05060663\nmedhhincome   0.1971310072   1.0000000 -0.74280330 -0.5823090  0.45672297\nPovertyRate  -0.1721973144  -0.7428033  1.00000000  0.5848120 -0.15673933\nunemprate    -0.1255690086  -0.5823090  0.58481204  1.0000000 -0.32627434\nmedvalue      0.0506066324   0.4567230 -0.15673933 -0.3262743  1.00000000\nmedrent       0.1434824928   0.6494977 -0.32058250 -0.4139894  0.60946764\npctwhite      0.0007742062   0.4334837 -0.58166274 -0.4583927  0.01479243\npctBlack      0.0305972149  -0.2081070  0.24067220  0.3002354  0.07662521\npctHispanic  -0.0610330071  -0.4470198  0.53817440  0.4107687 -0.24108925\npctAAPIalone  0.1179507879   0.1360442  0.05777953 -0.1516819  0.38403023\npctunder18    0.0075944281  -0.3886837  0.28931873  0.4263952 -0.48597184\npctover64    -0.0200934534   0.1116477 -0.40837729 -0.2236285 -0.08790793\nHSorlower    -0.0510755304  -0.6192728  0.38428550  0.5080771 -0.59138685\nBAorhigher    0.0317046620   0.5837037 -0.24483958 -0.4850706  0.71630822\n                 medrent      pctwhite    pctBlack pctHispanic pctAAPIalone\nPopulation    0.14348249  0.0007742062  0.03059721 -0.06103301   0.11795079\nmedhhincome   0.64949767  0.4334836763 -0.20810703 -0.44701977   0.13604425\nPovertyRate  -0.32058250 -0.5816627414  0.24067220  0.53817440   0.05777953\nunemprate    -0.41398938 -0.4583927470  0.30023542  0.41076874  -0.15168191\nmedvalue      0.60946764  0.0147924343  0.07662521 -0.24108925   0.38403023\nmedrent       1.00000000  0.0592656294 -0.01942961 -0.21839927   0.37309846\npctwhite      0.05926563  1.0000000000 -0.64391155 -0.72603098  -0.14608318\npctBlack     -0.01942961 -0.6439115534  1.00000000  0.05756055  -0.07150764\npctHispanic  -0.21839927 -0.7260309801  0.05756055  1.00000000  -0.16352352\npctAAPIalone  0.37309846 -0.1460831806 -0.07150764 -0.16352352   1.00000000\npctunder18   -0.47107334 -0.4866220916  0.28987714  0.52756318  -0.29072583\npctover64    -0.20439363  0.5440272257 -0.22702697 -0.42430798  -0.23991183\nHSorlower    -0.59290214 -0.4609030805  0.16871183  0.56358387  -0.25180077\nBAorhigher    0.67357448  0.3278345358 -0.19790460 -0.42390213   0.38422347\n               pctunder18    pctover64   HSorlower   BAorhigher\nPopulation    0.007594428 -0.020093453 -0.05107553  0.031704662\nmedhhincome  -0.388683691  0.111647722 -0.61927277  0.583703714\nPovertyRate   0.289318732 -0.408377288  0.38428550 -0.244839584\nunemprate     0.426395199 -0.223628488  0.50807715 -0.485070585\nmedvalue     -0.485971837 -0.087907931 -0.59138685  0.716308223\nmedrent      -0.471073339 -0.204393629 -0.59290214  0.673574479\npctwhite     -0.486622092  0.544027226 -0.46090308  0.327834536\npctBlack      0.289877141 -0.227026967  0.16871183 -0.197904602\npctHispanic   0.527563183 -0.424307981  0.56358387 -0.423902133\npctAAPIalone -0.290725828 -0.239911831 -0.25180077  0.384223470\npctunder18    1.000000000 -0.248306018  0.68045309 -0.718007353\npctover64    -0.248306018  1.000000000 -0.14789121 -0.003268322\nHSorlower     0.680453091 -0.147891209  1.00000000 -0.923184800\nBAorhigher   -0.718007353 -0.003268322 -0.92318480  1.000000000\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nozs_ma |> select(Population:medrent, pctwhite:BAorhigher) |> \n  na.omit() |> \n  DataExplorer::plot_correlation()\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/correlation-2-1.png){width=672}\n:::\n:::\n\n\nAn additional note to the code above is that we selected several continuous variables that we want to inspect, and removed NA values so that the correlation values can be correctly calculated.\n\n------------------------------------------------------------------------\n\nWhat can we do if we are interested in statistical associations between **categorical variables**? The typical approach is to summarise the values under each category and visualize them using **barcharts**.\n\nIn the following code, you can see our familiar `group_by` + `summarise` process used to calculate the average median house income by county in Massachusetts. This summarized table is then piped to `ggplot()` for visualization.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nozs_ma |> \n  group_by(county, DesignatedOZ) |>  \n  summarise(\n    Tracts = n(),\n    Income = mean(medhhincome, na.rm=TRUE)) |> \n  ggplot() +\n  geom_col(aes(x = county, y = Income, fill = DesignatedOZ), \n           position = \"dodge\") \n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/barchart-1.png){width=672}\n:::\n:::\n\n\n### Exercise 2\n\nTake a few minutes to read this bar chart below:\n\n![](../img/lab2-emp.png)\n\nHow can we modify our code above to replicate the bar chart in this image? You'll notice that you can achieve most of the features by tweaking our previous examples, plus a little bit more exploration. **In a new code chunk,** please copy and paste our last bar chart code, and try your best to address the following questions.\n\n1.  Please add the title, subtitle, x- and y-axis labels, and the data source annotation to your bar chart.\n2.  The background looks much cleaner. Please choose a theme template for your bar chart.\n3.  The x-axis labels are titled to 45 degrees. How can I achieve this? [Hint](https://ggplot2.tidyverse.org/reference/theme.html).\n4.  The labels on the y-axis are formatted in thousands with commas. This can be achieved by modifying the function `scale_y_continuous(labels = scales::percent)` we have seen before. [Hint](https://ggplot2.tidyverse.org/reference/scale_continuous.html).\n5.  Lastly, the counties are not arranged alphabetically, but rather by the income values mapped to the y-axis, starting from large to small. How can I achieve this? [Hint](https://blog.albertkuo.me/post/2022-01-04-reordering-geom-col-and-geom-bar-by-count-or-value/).\n\n# Combinations of basic graphs to create composite views\n\n## Boxplot and violin plots\n\nThe compilation of boxplot and violin plot can be effective ways to visualize key statistics and the number of observations throughout the range. There are a few new arguments in the following code for adjusting the aesthetics.\\\n`trim = FALSE`: If TRUE (default), trim the tails of the violins to the range of the data. If FALSE, don't trim the tails.\\\n`alpha = 0.5`: the transparency of the plotting area.\\\n`coord_flip()`: whether the y axis is displayed horizonally or vertically.\\\n`legend.position = \"none\"`: the position of legends (\"none\", \"left\", \"right\", \"bottom\", \"top\", or two-element numeric vector).\n\nYou can try to remove them or change their values to see how they work.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(ozs_ma) +\n  geom_violin(aes(x = DesignatedOZ, y = medhhincome, fill = DesignatedOZ), trim = FALSE, alpha = 0.5) +\n  geom_boxplot(aes(x = DesignatedOZ, y = medhhincome), colour = \"black\", width = .15, alpha = 0.8) +\n  labs(\n    x = \"Designated\",\n    y = \"Median Household Income\",\n    title = \"Distribution of Median Household Income\"\n  ) +\n  coord_flip() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/extra-1-1.png){width=672}\n:::\n:::\n\n\n## Scatterplot with marginal histograms\n\nThis requires a new package `ggExtra`. But the other syntax should be familiar now.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- ggplot(ozs_ma, aes(pctBlack, PovertyRate)) + \n  geom_point(aes(color = DesignatedOZ)) + \n  theme_bw()\nggExtra::ggMarginal(p, type = \"histogram\", groupFill = TRUE)\n```\n\n::: {.cell-output-display}\n![](lab2_files/figure-html/extra-2-1.png){width=672}\n:::\n:::\n\n\n# Work Products\n\nPlease submit **a .qmd file** and **a** **knitted HTML file** that shows your work and responses for each of the **two** **Exercises** included in this lab.\n\nIs there a distinguishable difference in economic conditions between designated and not-designated census tracts? Please comment on the graphics we have created, and discuss what you have found so far. Talk about any specific aspects you would like to further investigate on this question.\n\nAlso, briefly comment on your experience with R during this lab exercise. Please **upload your report to Canvas** **by the end of day, Tuesday, Nov 7.**\n\n### \n",
    "supporting": [
      "lab2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}