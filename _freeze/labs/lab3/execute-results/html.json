{
  "hash": "4970170d77ce0fe2ef02a16930215abc",
  "result": {
    "markdown": "---\ntitle: \"Place Opportunity\"\nformat: \n  html:\n    code-link: true\n---\n\n\nIn this lab, we will expand our understanding of opportunity maps, and more generally in standardizing and creating indexes from data. As we have discussed in class, opportunity maps and other indices are commonly used to describe multidimensional features across space. We measured a single dimension of place characteristics - racial distribution - last week. In this case, we'll produce a multidimensional measure of place.\n\nWe will focus on the *obesogenic environment* as one example of describing place opportunity. The concept of obesogenic environment highlights how social and environmental factors such as built environments, food availability, and socioeconomic status can influence behaviors, leading to increased obesity risk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(tigris)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n```\n:::\n\n```{.r .cell-code}\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLinking to GEOS 3.11.2, GDAL 3.6.2, PROJ 9.2.0; sf_use_s2() is TRUE\n```\n:::\n\n```{.r .cell-code}\nlibrary(osmdata)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nData (c) OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n```\n:::\n\n\n# Define Index Dimensions\n\nMultidimensional indices typically require a strong theoretical framework connecting concepts to measures designed to proxy or represent these concepts. Before deciding which indicators should be used in the index, it is necessary to clarify the *purpose* of the index. For example, an advocacy group wants to create an index to answer -- who is experiencing an unjust burden from an environment that can perpetuate unhealthy behaviors and contribute to obesity. The index proposed by the advocacy group should help guide efforts to create more equitable and health-promoting surroundings.\n\nThen how can we define the burden of an obesogenic environment? The advocacy group can, for example, identify factors based on two *dimensions*:\n\n-   Exposure to an obesity-inducing physical environment\n-   Population's vulnerability to obesity-inducing influences\n\n# Select Indicators\n\nIn this step, we identify the appropriate indicators, that represent each dimension or sub-dimension. To do this, you can consult literature that is relevant to your topic, you can also collaborate with domain experts, invite inputs from stakeholders, or conduct pilot studies to test different variables and their impact on the index's results. Arguably, there is no single definitive set of indicators and the variable selection process can be quite subjective and rely on data availability. The overarching guideline is to choose variables that align with the index's purpose, are justifiable, and are conceptually sound.\n\nToday we will first break our two dimensions into more operationalizable sub-dimensions:\n\n![](../img/lab3-dim.jpg)\n\nThen we can list a number of indicators that help describe our sub-dimensions. These indicators are commonly seen in opportunity measurements, and are publicly available from sources such as U.S. Census Bureau American Community Survey (ACS) and OpenStreetMap (OSM).\n\n| Sub-dimension                               | Indicator                                                                     | Data Source |\n|-----------------------|-------------------------------|------------------|\n| Exposure to an obesogenic food environment  | Proximity to unhealthy foods (e.g. fast-food stores, convenience stores, etc. | OSM         |\n| Exposure to an obesogenic food environment  | Lack of access to healthy foods (e.g. supermarkets, green groceries, etc.)    | OSM         |\n| Exposure to physical activity opportunities | Proximity to Health-inducing Places (e.g. parks, playgrounds, etc.)           | OSM         |\n| Socioeconomic Status                        | Proportion Households Below Poverty                                           | ACS         |\n| Socioeconomic Status                        | Proportion of Housing Cost Burdened                                           | ACS         |\n| Socioeconomic Status                        | Proportion Households Receiving Food Stamps/SNAP                              | ACS         |\n| Household Characteristics                   | Proportion of Single Families with Children                                   | ACS         |\n| Work and Transportation                     | Proportion of Unemployment                                                    | ACS         |\n| Work and Transportation                     | Proportion of No-vehicle Working Households                                   | ACS         |\n\n## ACS data\n\nI went ahead and downloaded the following ACS tables at the census tract level for all tracts in Cook County. Then in each table, I calculated the indicators by dividing the amount of interest by the total population/households. The script I used is `lab3_acs.R`:\n\n| Table  | Description               |\n|--------|---------------------------|\n| B17001 | Poverty Rate              |\n| B25106 | Housing Cost Burden       |\n| B22007 | Recipients of Food Stamps |\n| B09002 | Families with Children    |\n| DP03   | Unemployment              |\n| B08141 | Drive to Work             |\n\nUse the `source()` command to run the entire script to bring the variables to our current work environment. You will now see a bunch of new variables in the Environment panel, each contains a proportion value representing the ACS indicators.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"../srt/lab3_acs.R\")\n```\n:::\n\n\nThen we are going to combine these individual tables into a single dataset, based on a common field they share - `GEOID`. Typically, we use a series of `join` functions provided by `dplyr` to perform such a combination. `Join` works like this:\n\n`*_join(x, y, by = \"key name\")`\n\nThe `*_join` could be `left_join`, `right_join`, `full_join`, or `inner_join`...Here are some illustrations to illustrate how joins work.\n\n![](../img/lab3-venn.png)\n\n`x` and `y` are two data frames. The `by` attribute is used to name the common identifier column present in both `x` and `y`. If you're lucky, they'll have the same name. If you're unlucky, you'll have to type a bit more: `by = c(\"name1\" = \"name2\")`, assuming \"name1\" is the name of the key column in `x` and \"name2\" is that in `y`.\n\nFor instance, we can do a `left_join` on, based on the `GEOID` field\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleft_join(B17001, B25106, by = \"GEOID\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 1332 features and 3 fields (with 1 geometry empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -88.26364 ymin: 41.46971 xmax: -87.52416 ymax: 42.15426\nGeodetic CRS:  NAD83\nFirst 10 features:\n         GEOID  p_poverty p_cost_burden                       geometry\n1  17031822400 0.26231091     0.4266870 MULTIPOLYGON (((-87.79876 4...\n2  17031740100 0.10364619     0.2723440 MULTIPOLYGON (((-87.70137 4...\n3  17031530501 0.28267297     0.3466135 MULTIPOLYGON (((-87.64191 4...\n4  17031830300 0.09717590     0.3907347 MULTIPOLYGON (((-87.6934 41...\n5  17031750300 0.02061038     0.1799163 MULTIPOLYGON (((-87.6912 41...\n6  17031826303 0.14950785     0.4382872 MULTIPOLYGON (((-87.59781 4...\n7  17031826500 0.33795905     0.5110132 MULTIPOLYGON (((-87.63427 4...\n8  17031827801 0.11708988     0.4567474 MULTIPOLYGON (((-87.61707 4...\n9  17031825900 0.21960227     0.2767528 MULTIPOLYGON (((-87.54895 4...\n10 17031822601 0.04627432     0.3118844 MULTIPOLYGON (((-87.76741 4...\n```\n:::\n:::\n\n\nA `join` function only with respect to two datasets at a time. Let's introduce a more efficient strategy here, using the `purrr` package's `reduce()` function combined with `left_join()` :\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Make the ACS dataset ----------   \nacs <- list(B17001, B25106, B22007, B11003, DP03, B08141, B01001) %>% \n  reduce(left_join, by = \"GEOID\")\n```\n:::\n\n\nWe now have an assembled ACS table for Cook County. Run the following block to cut it to the Chicago area, as we did before:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_place <- places(state = \"IL\") |> \n  filter(NAME == \"Chicago\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRetrieving data for the year 2021\n```\n:::\n\n```{.r .cell-code}\nacs_data <- acs |>\n  st_intersection(chi_place) |>\n  select(GEOID, p_poverty:pop)\n```\n:::\n\n\nThe `acs_data` dataset now contains all the ACS variables we need for this exercise. Try using `ggplot` to plot out a few variables to see if it makes sense spatially.\n\nNow we are going to move on to obtaining point-of-interest (POI) data from OpenStreetMap. Remove all the intermediary variables by running the line below - this keeps only `acs_data` in our working environment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list=setdiff(ls(), \"acs_data\"))\n```\n:::\n\n\n## OSM data\n\nOpenStreetMap (OSM) is a global open-access mapping project. By allowing anyone to contribute, OSM enables the real-time evolution of its database and offers convenient options for downloading data. OSM handles download queries through the **overpass API**. But in this lab, we will use `osmdata` R package, which simplifies download queries so that OSM data can be extracted with very little understanding of the overpass query syntax. In order to obtain data from OSM, you will need to specify:\n\n-   a bounding box\n-   key-value pairs\n\n### The bounding box\n\nA bounding box is like a window of where you want to clip a piece of map. It can be defined by manually specifying two latitude-longitude pairs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# (lat, lon) of Lower left and Upper right corners \nbbox = c(41.644531,-87.940101,42.0230396,-87.5240812)\n```\n:::\n\n\nIn most cases, they can be directly identified by character strings.\n\n`bbox = 'Chicago, IL, USA'`\n\nHowever, recently there seems to be some issues with `bbox` direct address query. I implemented [a workaround here](https://stackoverflow.com/questions/76835293/error-when-querying-osmdata-package-http-405-method-not-allowed) so that we can still obtain a bounding box by entering a place name.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbbox <- sf::st_bbox(nominatimlite::geo_lite_sf(\n  address = \"Chicago, IL, USA\", \n  points_only = FALSE))   \n```\n:::\n\n\n### The key-value pairs\n\nAn overpass query `opq` starts with the bounding box like this:\n\n`q <- opq(bbox)`\n\nFollowing the initial `opq()` call, we will build queries by adding one or more *features*, which are specified in terms of key-value pairs. The \"values\" can be understood as items on the map such as restaurants, while the \"keys\" are categories. [Here](https://wiki.openstreetmap.org/wiki/Map_Features) is a complete list of key-value pairs on OSM. Due to its crowd-sourced feature, not all of them are available for every city, but those related to streets, amenities (food, shops) and are typically abundant and available.\n\nFor example, all restaurants, bars, and fast foods are categorized in OSM under `key=amenity`, so that a query of all restaurants within the boundary box of Chicago can be constructed as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrestaurant <- opq(bbox)|>   \n  add_osm_feature(key = \"amenity\", value = c(\"restaurant\")) |>  \n  osmdata_sf() \n```\n:::\n\n\nThe retrieved OSM object is a huge list that includes numerous attributes; What we need is an `sf` object named `osm_points` nested in this list. Let's extract only the name and the attached geometry of this object:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrestaurant <- restaurant$osm_points |> select(name)\n```\n:::\n\n\nClick open `restaurant`, you will notice that the names will be missing for a lot of places due to OSM's crowdsourced feature. But that's fine, we can go ahead and plot it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot()+\n  geom_sf(data = restaurant)\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n### Aligning spatial objects\n\nGiven the tract-level polygons obtained in the previous step and the point data provided here, it makes sense to perform a spatial join to assess their overlap and determine the number of points within each polygon. Let's start by testing whether this approach is feasible:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#st_intersects(acs_data, restaurant)\n```\n:::\n\n\nYou will be notified that due to some errors about \"st_crs\", this spatial join could not be properly handled. Coordinate reference systems (CRS) are like a set of instructions that help us accurately translate locations on the Earth's surface into positions on maps. Maps using different CRS do not align places in the same way. We can check the CRS used by these two spatial objects using `st_crs`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nst_crs(acs_data)\nst_crs(restaurant)\n```\n:::\n\n\nThe `acs_data` is stored in the NAD83 CRS, with an EPSG code 4269. The `restaurant`data downloaded from OSM is stored in the WGS84 CRS, EPSG 4326. Both are widely adopted CRSs in North America, but in order to make them work with each other, we have to make sure they are spatially lined up.\n\nWe will use `st_transform` to convert the CRS of either one to match the other. The only input we need here is the target EPGS code. EPSG codes are an international standard for referencing coordinate reference systems so that we have handy 4 digits to represent the entire text blocks.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrestaurant <- restaurant |> st_transform(4269)\n```\n:::\n\n\n### Construct indicators\n\nTo streamline this \"download - extract - transform\"process, we can create a function to extract the specific elements required.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# I name the function \"get_osm\". \n# The inputs are place name and the key-value pair\n# The output is a spatial point sf object that stores the locations of POIs.\nget_osm <- function(place, key, value){\n  bbox <- sf::st_bbox(nominatimlite::geo_lite_sf(\n    address = place,\n    points_only = FALSE))\n  \n  temp <- opq(bbox) |>\n    add_osm_feature(key = key, value = value) |>\n    osmdata_sf()\n  \n  df <- temp$osm_points |> select(name) |>\n    st_transform(4269)\n  return(df)\n}\n```\n:::\n\n\nLet's go ahead and download the following\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplayground <- get_osm(\"Chicago, IL, USA\", \"leisure\", \"playground\")\npark <- get_osm(\"Chicago, IL, USA\", \"leisure\", \"park\")\nsupermarket <- get_osm(\"Chicago, IL, USA\", \"shop\", \"supermarket\")\ngreengrocer <- get_osm(\"Chicago, IL, USA\", \"shop\", \"greengrocer\")\nfastfood <- get_osm(\"Chicago, IL, USA\", \"amenity\", \"fast_food\")\nconvenience <- get_osm(\"Chicago, IL, USA\", \"shop\", \"convenience\")\n```\n:::\n\n\nOnce the six variables are generated (check if you have them in the Environment tab), we will do a spatial join to count the number of points within each ACS tract polygon. `st_intersects` performs a spatial intersection between two geometries and returns a logical value indicating whether the intersection occurs (True - there are points in this polygon, and False - no point is in this polygon). We then apply `lengths` to the result of `st_intersects` to count the number of TRUE values, which is the sum of the points that intersect with the polygon.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# The `bind_cols` brings multiple vectors together to make a data frame\nosm_data <- bind_cols(\n  lengths(st_intersects(acs_data, playground)),\n  lengths(st_intersects(acs_data, park)),\n  lengths(st_intersects(acs_data, supermarket)),\n  lengths(st_intersects(acs_data, greengrocer)),\n  lengths(st_intersects(acs_data, fastfood)),\n  lengths(st_intersects(acs_data, convenience))\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...4`\n• `` -> `...5`\n• `` -> `...6`\n```\n:::\n\n```{.r .cell-code}\ncolnames(osm_data) <- c(\"playground\", \"park\", \"supermarket\",\n\"greengrocer\", \"fastfood\", \"convenience\")\n```\n:::\n\n\nConceptually we are using the number of POIs to assess whether the surrounding physical environment plays a role in causing obesity. This corresponds to our sub-dimensions like this:\n\n| Object             | Description                                                  | Description                         |\n|------------------|---------------------------|---------------------------|\n| Playground         | Number of areas designed for children to play                | Proximity to Health-inducing Places |\n| Park               | Number of parks, usually urban (municipal)                   | Proximity to Health-inducing Places |\n| Supermarket        | Number of large stores with groceries and other items        | Proximity to healthy foods          |\n| Green Grocery      | Number of shops focused on selling vegetables and fruits     | Proximity to healthy foods          |\n| Fast Food          | Number of fast food restaurants                              | Proximity to unhealthy foods        |\n| Convenience Stores | Number of small local shops carrying a small subset of items | Proximity to unhealthy foods        |\n\n**Pause and reflect:**\n\n-   Is it suitable/acceptable to use points to represent parks and playgrounds in this case?\n-   How does the tract-based count represent proximity and accessibility to these amenities? For instance, does a tract that has 5 supermarkets certainly mean people living here have better access to fresh food than those living in a tract that has 2?\n\nTo partially address the limitation of area-based raw counts, we will perform one more step - calculating the density of the OSM amenities per thousand people.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- bind_cols(acs_data, osm_data)\n\ndata <- data |>    \n  mutate(playground = ifelse(pop > 0, round(playground/(pop/1000), 1), NA),    \n         park = ifelse(pop > 0, round(park/(pop/1000), 1), NA),          \n         supermarket = ifelse(pop > 0, round(supermarket/(pop/1000), 1), NA),   \n         greengrocer = ifelse(pop > 0, round(greengrocer/(pop/1000), 1), NA),   \n         fastfood = ifelse(pop > 0, round(fastfood/(pop/1000), 1), NA),        \n         convenience = ifelse(pop > 0, round(convenience/(pop/1000), 1),NA))\n```\n:::\n\n\nWe have compiled the necessary dataset that incorporates indicators from both dimensions. Now, let's remove intermediary variables in the working environment and prepare to create the index.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(list=setdiff(ls(), \"data\"))\n```\n:::\n\n\n# Create Composite Indices\n\nThere are, of course, various methods to combine variables. We are going to create a straightforward and effective additive index. But before that, we need to preprocess our data to make sure they are compatible and can be properly combined into an index.\n\n## Standardize indicators\n\nIt is often challenging, if not impractical, to compare data that come with different units and ranges. For example, it does not make too much sense to add up a variable such as median household values, which are measured in thousands, and a variable like poverty rate, which is measure in percentage. In many statistical analyses, such as multivariate linear regression, standardize your data is usually an essential first step to prevent certain variables from dominating the analysis due to their larger numerical values.\n\nZ-score standardization converts data from various distributions into a common *unit* of measurement, which is the number of standard deviation from the mean. This conversion enables data points, regardless of their original spread, to be expressed in a consistent and comparable manner.\n\nA z-score can be calculated by subtracting from a given observation the mean of all observations and then dividing by the standard deviation of all observations. R has us covered here - the `scale()` function does exactly the same thing. Here we use a `mutate_at()` function to perform the same alteration upon multiple variables we select. Take a look at the documentation for `mutate_at()`, the `list` argument allows you to modify existing columns in place.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscore <-\n  data |>\n  mutate_at(\n    vars(\n      p_poverty,\n      p_cost_burden,\n      p_food_assist,\n      p_children,\n      p_unemp,\n      p_transit_dep,\n      playground,\n      park,\n      supermarket,\n      greengrocer,\n      fastfood,\n      convenience\n    ),\n    list(scale)\n  )\n```\n:::\n\n\n## Rescale indicators\n\nNow we want to transform our data points, currently spanning various value ranges, into a uniform range such as between 0 and 1. Min-max normalization is a commonly used method for achieving this. It adjusts the ranges while maintaining the relative differences between the values.\n\n$$\nx_{rescaled}=\\frac{x-min(x)}{max(x)-min(x)}\n$$\n\nIn R, the function we are going to use is `rescale` in the `scales` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scales)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'scales'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    discard\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:readr':\n\n    col_factor\n```\n:::\n\n```{.r .cell-code}\nscore <-\n  score |>\n  mutate_at(\n    vars(\n      p_poverty,\n      p_cost_burden,\n      p_food_assist,\n      p_children,\n      p_unemp,\n      p_transit_dep,\n      playground,\n      park,\n      supermarket,\n      greengrocer,\n      fastfood,\n      convenience\n    ),\n    list(rescale)\n  )\n```\n:::\n\n\n## Specify the directions\n\nHigh values in indicators may represent beneficial or detrimental conditions - in some cases, higher values are \"good\", and in some cases, lower values are \"good\". We need to make sure that those values are all moving in the same direction so that when we combine them they do not counter-act each other.\n\nLet's list our indicators again and propose potential directions for each of them.\n\n-   **Negative:** For a variable labeled **Negative**, higher values are likely to indicate lower levels of opportunity.\n\n-   **Positive:** Far a variable labeled **Positive**, higher values are likely to indicate higher levels of opportunity.\n\n| Indicator     | Description                                                  | Relationship to Obesogenic Environment | Sub-dimension |\n|---------------|-----------------------------|---------------|---------------|\n| p_poverty     | Proportion Households Below Poverty                          | Positive                               | Vulnerability |\n| p_cost_burden | Proportion of Housing Cost Burdened                          | Positive                               | Vulnerability |\n| p_food_assist | Proportion Households Receiving Food Stamps/SNAP             | Positive                               | Vulnerability |\n| p_children    | Proportion of Single Families with Children                  | Positive                               | Vulnerability |\n| p_unemp       | Proportion of Unemployment                                   | Positive                               | Vulnerability |\n| p_transit_dep | Proportion of No-vehicle Working Households                  | Positive                               | Vulnerability |\n| playground    | Number of areas designed for children to play                | Negative                               | Exposure      |\n| park          | Number of parks, usually urban (municipal)                   | Negative                               | Exposure      |\n| supermarket   | Number of large stores with groceries and other items        | Negative                               | Exposure      |\n| greengrocer   | Number of shops focused on selling vegetables and fruits     | Negative                               | Exposure      |\n| fastfood      | Number of fast food restaurants                              | Positive                               | Exposure      |\n| convenience   | Number of small local shops carrying a small subset of items | Positive                               | Exposure      |\n\nWhen we are creating an additive index, we can transform values so that they are moving in the same direction by simply switching the sign on values that need to be reversed (e.g. multiply by -1).\n\n## Aggregate the index\n\nWe are finally going to assemble our composite index, where standardized values are simply added together. Based upon the above table, Here's what that would look like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscore <- score |>\n  rowwise() |>\n  mutate(\n    exp_index = sum(\n      playground * (-1),\n      park * (-1),\n      supermarket * (-1),\n      greengrocer * (-1),\n      fastfood,\n      convenience,\n      na.rm = TRUE\n    ),\n    vul_index = sum(\n      p_poverty,\n      p_cost_burden,\n      p_food_assist,\n      p_children,\n      p_unemp,\n      p_transit_dep,\n      na.rm = TRUE\n    ),\n    tot_index = exp_index + vul_index\n  ) |> \n  ungroup()\n```\n:::\n\n\nDid you notice `rowwise()`? Typically, if we were to ask `dplyr` to mutate by providing a sum, it would do so by column. `rowwise()` modifies this and asks for something to happen across a data observation (row) instead of by column.\n\nOk - now we have subindex values as well as a total index value. We could analyze these and interpret them as is, but one more step would make these easier to interpret. For an index, it's reasonable to anticipate a value falling within the range of 0 to 100. We can use `rescale` again with specified ranges\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscore <-\n  score |>\n  mutate(\n    exp_index = rescale(exp_index, to = c(0, 100)),\n    vul_index = rescale(vul_index, to = c(0, 100)),\n    tot_index = rescale(tot_index, to = c(0, 100))\n  )\n```\n:::\n\n\nLet's make a simple histogram of values for our `tot_index` measure:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(score) +\n  geom_histogram(aes(x = tot_index), bins = 50) +\n  labs(title = \"Obesogenic Environment Index: Histogram\",\n       x = \"Obesogenic Environment Index\",\n       y = \"Count\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nTo make a map,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(score) + \n  geom_sf(aes(fill = tot_index))\n```\n\n::: {.cell-output-display}\n![](lab3_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n# Work product\n\nSubmit **a short report (no more than two pages)** addressing the following two questions and sharing your insights. Feel free to include any supplementary materials if they help to convey your conc\n\n1.  Place your index alongside the racial distribution results from last week using any method you prefer (creating multiple maps, generating scatter plots, calculating correlation values, etc.). Comment on any relationship or patterns if you discover any.\n2.  Discuss what we can learn from the obesogenic environment index in the broad context drawing upon articles on [social determinants of health](https://www.cdc.gov/about/sdoh/index.html).\n\n**Please upload the report to Canvas by the end of day, Tuesday, Nov 14.**\n\n## References\n\n-   [Creating Composite Indices Using ArcGIS: Best Practices](https://www.esri.com/content/dam/esrisites/en-us/media/technical-papers/creating-composite-indices-using-arcgis.pdf). An ESRI Technical Paper. February, 2023.\n-   [Technical Documentation for the CDC Environmental Justice Index](https://www.atsdr.cdc.gov/placeandhealth/eji/docs/EJI-2022-Documentation-508.pdf). 2022\n-   [UN Human Development Index Technical Notes](https://hdr.undp.org/sites/default/files/2021-22_HDR/hdr2021-22_technical_notes.pdf). 2022.\n-   Townsend, P. (1987). [\"Deprivation\" Journal of Social Polic](https://doi.org/10.1017/S0047279400020341)y, 16(2), 125-146.\n",
    "supporting": [
      "lab3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}